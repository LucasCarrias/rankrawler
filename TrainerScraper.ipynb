{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seleniumwire import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "import pymysql\n",
    "import re\n",
    "import time\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host='127.0.0.1', user='root', passwd='210909', db='mysql', charset='utf8')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"USE trainingdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Page:\n",
    "    \n",
    "    def __init__(self, url):      \n",
    "        self.url = url\n",
    "        self.domain = urlparse(url).netloc\n",
    "        \n",
    "    def get_page_info(self,search_keyword=''):        \n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.header_overrides = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36'}\n",
    "        try:\n",
    "            driver.get(self.url)\n",
    "            bs = BeautifulSoup(driver.page_source, 'html5lib')\n",
    "            self.url = driver.current_url\n",
    "            self.has_cookies = True if len(driver.get_cookies()) > 0 else False\n",
    "            self.status_code = [request.response.status_code for request in driver.requests if request.response][0]\n",
    "        finally:\n",
    "            driver.close()   \n",
    "        \n",
    "        self.last_access = datetime.now()\n",
    "        self.lang = self.get_tag_attr_text(bs, 'html', 'lang')\n",
    "        self.title = self.get_tag_text(bs, 'title')\n",
    "        self.h1 = self.get_tag_text(bs, 'h1')\n",
    "        self.description = self.get_tag_attr_text(bs, 'meta', 'name', 'description', target='content')\n",
    "        self.keywords = self.get_tag_attr_text(bs, 'meta', 'name', 'keywords', target='content')\n",
    "        self.has_viewport = True if self.get_tag_attr_text(bs, 'meta', 'name', 'viewport') is not None else False\n",
    "        \n",
    "        if search_keyword != '':\n",
    "            self.search_results =  self.get_search_results(bs, search_keyword)    \n",
    "    \n",
    "    def get_search_results(self, bs_obj, keyword):\n",
    "        macthes = {'in_h1':False,'in_title':False,'in_description':False ,'body':0}\n",
    "        for word in set(keyword.split(' ')):\n",
    "            if not macthes['in_h1'] and self.h1 is not None:\n",
    "                macthes['in_h1'] = len(re.findall(f'(?i){word}', self.h1)) > 0\n",
    "            if not macthes['in_title'] and self.title is not None:\n",
    "                macthes['in_title'] = len(re.findall(f'(?i){word}', self.title)) > 0\n",
    "            if not macthes['in_description'] and self.description is not None:\n",
    "                macthes['in_description'] = len(re.findall(f'(?i){word}', self.description)) > 0\n",
    "            if bs_obj.find('body') is not None:\n",
    "                macthes['body'] += len(re.findall(f'(?i){word}', bs_obj.find('body').get_text()))        \n",
    "        macthes['body'] = int(macthes['body']/len(set(keyword.split(' '))))        \n",
    "        return macthes\n",
    "    \n",
    "    def get_links(self, bs_obj):\n",
    "        if bs_obj is None:\n",
    "            return\n",
    "        links = set()\n",
    "        internal_links = set()\n",
    "        external_links = set()\n",
    "        raw_url = f\"{urlparse(self.url).scheme}://{self.domain}\"\n",
    "        \n",
    "        if self.bs_obj.find(\"a\") is not None:            \n",
    "            for link in self.bs_obj.find_all(\"a\", href=re.compile(r\"^\\/?^[^#].+\")):\n",
    "                result = link.attrs[\"href\"]\n",
    "                if re.match(r'^//', result):\n",
    "                    self.external_links.add(\"http:\" + result)\n",
    "                elif result[0] == \"/\":\n",
    "                    self.internal_links.add(raw_url + result)\n",
    "                else:\n",
    "                    if re.match(r'^https?', result) is not None:\n",
    "                        self.external_links.add(result)\n",
    "                    elif re.match(r'^www', result) is not None:\n",
    "                        self.external_links.add(\"https://\" + result)\n",
    "                    else:\n",
    "                        self.internal_links.add(\"/\".join([raw_url, result]))\n",
    "            return self.internal_links | self.external_links\n",
    "    \n",
    "    def print_info(self):\n",
    "        for key, item in self.__dict__.items():\n",
    "            print(str(key) + \":\" + str(item))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_tag_text(bs_obj, tag):\n",
    "        if bs_obj.find(tag) is not None:\n",
    "            return bs_obj.find(tag).get_text().strip()\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_tag_attr_text(bs_obj, tag, attr, attr_value='.*', target=''):\n",
    "        result = bs_obj.find(tag, {f\"{attr}\":re.compile(f'(?i){attr_value}')})\n",
    "        if result is not None:            \n",
    "            if target != '':\n",
    "                return result[target]\n",
    "            return result[attr]\n",
    "        return None\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Domain:\n",
    "    def __init__(self, netloc, ignore=False):\n",
    "        self.netloc = netloc\n",
    "        self.ignore = ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerScraper:\n",
    "    \n",
    "    class FoundPage(Page):\n",
    "        def __init__(self, url, score):\n",
    "            super().__init__(url)\n",
    "            self.score = score\n",
    "    \n",
    "    def __init__(self,*, ignored_domains=[]):   \n",
    "        self.visited_pages = set()\n",
    "        self.visited_urls = set()\n",
    "        self.ignored_domains = ignored_domains\n",
    "        \n",
    "    def get_google_results(self, keyword, amount=10):\n",
    "        start = time.perf_counter()\n",
    "        self.update_domains()\n",
    "        self.save_config(keyword, amount)\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.header_overrides = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36'}\n",
    "        total_ranks = 0\n",
    "        while len(self.visited_urls) + 1 < amount:            \n",
    "            query_keyword = \"+\".join(keyword.split(\" \"))            \n",
    "            print(f'[{keyword}] Getting response from google.com: ' + str(len(self.visited_urls)))\n",
    "            if len(self.visited_urls) == 0:\n",
    "                driver.get(f'https://www.google.com/search?client=ubuntu&channel=fs&q={query_keyword}&ie=utf-8&oe=utf-8')\n",
    "            else:\n",
    "                driver.get(f'https://www.google.com/search?client=ubuntu&channel=fs&q={query_keyword}&ie=utf-8&oe=utf-8&start={len(self.visited_urls)+1}')\n",
    "                \n",
    "            bs = BeautifulSoup(driver.page_source, 'html5lib')\n",
    "            \n",
    "            try:\n",
    "                with concurrent.futures.ProcessPoolExecutor() as executor:                            \n",
    "                    processes = []\n",
    "                    for rank, url in enumerate(self.get_urls(bs)):\n",
    "                        if url not in self.visited_urls and not self.is_already_searched(url, keyword):\n",
    "                            self.visited_urls.add(url)\n",
    "                            processes.append(executor.submit(self.get_page_results, url, keyword, (rank+1)+total_ranks))\n",
    "                    total_ranks = max(total_ranks, len(self.visited_urls))   \n",
    "\n",
    "                    for result in concurrent.futures.as_completed(processes):\n",
    "                        result = result.result()\n",
    "                        if result is not None:\n",
    "                            self.visited_pages.add(result)\n",
    "                            self.save_search(keyword, result.score, result)\n",
    "            finally:\n",
    "                conn.commit()\n",
    "        driver.close()\n",
    "        print(f\"Searching for {keyword} done in {round(time.perf_counter() - start, 2)} second(s)\")\n",
    "        \n",
    "    def get_page_results(self, url, keyword, score):            \n",
    "        found_page = self.FoundPage(url, score)        \n",
    "        if found_page.domain in self.ignored_domains:\n",
    "            return None\n",
    "        self.save_domain(found_page.domain)\n",
    "        print(\"Looking at: \" + url)\n",
    "        try:\n",
    "            found_page.get_page_info(keyword)            \n",
    "            self.save_page(found_page)\n",
    "            found_page.print_info()\n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            self.save_domain(found_page.domain, ignore=True)\n",
    "            self.update_domains()\n",
    "            print(f\"Error in: {url}\\n\")\n",
    "            return None        \n",
    "        return found_page\n",
    "    \n",
    "    def get_urls(self, bs_obj):        \n",
    "        for div in bs_obj.find_all('div', class_='srg'):    \n",
    "            for a in div.find_all('a'):\n",
    "                if not a.find('span') and 'webcache' not in a['href'] and 'class' not in a.attrs:\n",
    "                    yield a['href']\n",
    "    \n",
    "    def update_domains(self):\n",
    "        cur.execute(f\"SELECT * FROM domain where blackListed = 1\")\n",
    "        for bad_domain in cur.fetchall():\n",
    "            self.ignored_domains.append(bad_domain[1])\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_already_searched(url, keyword):\n",
    "        cur.execute(f\"SELECT idPage FROM page WHERE url like '{url}'\")\n",
    "        q = cur.fetchone()\n",
    "        if q is None:\n",
    "            return False\n",
    "        id_page = q[0]\n",
    "        cur.execute(f\"SELECT idConfig FROM config WHERE keyword like '{keyword}'\")\n",
    "        q = cur.fetchone()\n",
    "        if q is None:\n",
    "            return False\n",
    "        id_config = q[0]\n",
    "        cur.execute(f\"SELECT * FROM search WHERE idPage = {id_page} and idConfig = {id_config}\")\n",
    "        return True if cur.fetchone() else False\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_domain(netloc, ignore=False):\n",
    "        cur.execute(f\"SELECT netloc FROM domain where netloc like '{netloc}'\")\n",
    "        if not cur.fetchone():\n",
    "            cur.execute(f\"INSERT INTO domain (netloc, blackListed) values ('{netloc}', {1 if ignore else 0})\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def save_config(keyword, amount):\n",
    "        cur.execute(f\"SELECT keyword FROM config where keyword like '{keyword}'\")\n",
    "        if not cur.fetchone():\n",
    "            cur.execute(f\"INSERT INTO config (keyword, maxPages) values ('{keyword}', {amount})\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def save_page(found_page):    \n",
    "        cur.execute(f\"SELECT idDomain FROM domain where netloc like '{found_page.domain}'\")\n",
    "        domain_id = cur.fetchone()[0]\n",
    "        cur.execute(\"INSERT INTO page (url, idDomain, hasTitle, hasH1, hasDescription, hasKeywords, hasViewport) values \" \\\n",
    "                    f\"('{found_page.url}', {domain_id},\" \\\n",
    "                    f\"{1 if found_page.title else 0},{1 if found_page.h1 else 0}, {1 if found_page.description else 0}, \" \\\n",
    "                    f\"{1 if found_page.keywords else 0}, {1 if found_page.has_viewport else 0})\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def save_search(keyword, score, found_page):\n",
    "        cur.execute(f\"SELECT idConfig FROM config where keyword like '{keyword}'\")\n",
    "        config_id = cur.fetchone()[0]\n",
    "        cur.execute(f\"SELECT idPage FROM page where url like '{found_page.url}'\")\n",
    "        page_id = cur.fetchone()[0]\n",
    "        cur.execute(f\"INSERT INTO search (idConfig, idPage, score) values ({config_id}, {page_id}, {score})\")\n",
    "        \n",
    "        cur.execute(f\"SELECT max(idSearch) FROM search\")\n",
    "        search_id = cur.fetchone()[0]\n",
    "        results = found_page.search_results\n",
    "        cur.execute(\"INSERT INTO result (idSearch, matchesInBody, keywordInTitle, keywordInDescription, keywordInH1) values \" \\\n",
    "                    f\"({search_id}, {results['body']}, {1 if results['in_title'] else 0}, {1 if results['in_description'] else 0}, {1 if results['in_h1'] else 0})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainerScraper(ignored_domains=['www.youtube.com', 'www.instagram.com', 'twitter.com', 'www.facebook.com'])\n",
    "trainer.get_google_results('amor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-35d24073bf41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisited_pages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "for page in sorted(trainer.visited_pages, key=lambda x : x.score):\n",
    "    print()\n",
    "    page.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainer.visited_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainer.visited_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, page in enumerate(sorted(trainer.visited_pages, key=lambda x: x.score)):\n",
    "    \n",
    "    page.print_info()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in trainer.visited_urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
